{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Transfer learning the last layer using the bottleneck as input\n",
    "\n",
    "### to decide the further transfer learning models size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import random\n",
    "import errno\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "from numpy import set_printoptions\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from save_resnet18_test_scores import predict_via_single_model\n",
    "from ImageFolderData import ImageFolder\n",
    "from Resnet101Layer4DinputData import leaf_resnet_eval_layer_tensor\n",
    "from DataWDistilledLogits import leaf_resnet_train_distill\n",
    "from get_result_file_paths import get_saved_logits_fn, get_result_file_paths\n",
    "from ResNet101BaseModel import ResNet101FC\n",
    "from ResNet101TransferModel import NewModelFromResNet101BottleNeck\n",
    "from ResNet18Model import ResNet18FC\n",
    "from resnet18_run import share_parser\n",
    "from initial_transferlearn_models import resnet18Base, resnet34Base, resnet50Base, resnet101Base, resnet152Base, resnet18t, resnet34t, resnet50t, resnet101t, resnet152t\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = share_parser()\n",
    "args = parser.parse_args([])\n",
    "args.dataseparate='50-50'\n",
    "#https://stackoverflow.com/questions/41961949/google-oauth-inside-jupyter-notebook\n",
    "assert args.train_size >= args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Namespace(T=3.5, arch='resnet18', batch_size=100, beta1=0.5, cuda=True, dataroot='/home/h/Downloads/plantvillage_deeplearning_paper_dataset', dataseparate='50-50', dataset='leaf', datasettype='train', distill='False', dr=0.5, epochs=30, eta=20.0, has_weights='True', lr=0.0002, no_cuda=False, num_channels=3, num_hidden_neuron=64, resume='', rlr=0.003, saveroot='/media/h/15210519917/resnet18', seed=5306, softlogits='False', start_epoch=0, test_batch_size=100, train_size=100, transferinputdir='bottleneck_tensors_labels/5306seed_layer3', wd=0.0005)\n"
     ]
    }
   ],
   "source": [
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "print(args.cuda)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  5306\n"
     ]
    }
   ],
   "source": [
    "if args.seed is None:\n",
    "    args.seed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", args.seed)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 2, 'pin_memory': True} if args.cuda else {}\n",
    "data_separate = args.dataseparate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(arch):\n",
    "    if arch == 'resnet18':\n",
    "        transfer_model = resnet18t()\n",
    "    elif arch == 'resnet34':\n",
    "        transfer_model = resnet34t()\n",
    "    elif arch == 'resnet50':\n",
    "        transfer_model = resnet50t()\n",
    "    elif arch == 'resnet101':\n",
    "        transfer_model = resnet101t()\n",
    "    elif arch == 'resnet152':\n",
    "        transfer_model = resnet152t()\n",
    "\n",
    "    CE_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    if args.cuda:\n",
    "        transfer_model = torch.nn.DataParallel(transfer_model).cuda()\n",
    "        CE_loss = CE_loss.cuda()\n",
    "    model_dir = os.path.join('/media/h/15210519917','initial_tl', arch)\n",
    "    model_path = os.path.join(model_dir, data_separate+'_'+str(29)+'.pth.tar')\n",
    "    preds_labels_file = os.path.join(model_dir, data_separate+'_'+str(29)+'.pt')\n",
    "    leaf_test_loader =  torch.utils.data.DataLoader(\n",
    "        leaf_resnet_eval_layer_tensor(root_dir = args.dataroot\n",
    "                                      , data_type='test',data_separate=data_separate\n",
    "                                      ,transf_in_dir='bottleneck_tensors_labels/'+arch\n",
    "                                     ), \n",
    "        batch_size=args.test_batch_size, shuffle=False, **kwargs)\n",
    "    if os.path.exists(preds_labels_file) == False:\n",
    "            if os.path.isfile(model_path):\n",
    "                print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "                checkpoint = torch.load(model_path)\n",
    "                transfer_model.load_state_dict(checkpoint['state_dict'])\n",
    "                print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                      .format(model_path, checkpoint['epoch']))\n",
    "            else:\n",
    "                print(\"=> no checkpoint found at '{}'\".format(model_path))\n",
    "\n",
    "    transfer_model.eval()\n",
    "\n",
    "    predict_via_single_model(leaf_test_loader, transfer_model, CE_loss, args.test_batch_size, preds_labels_file=preds_labels_file, cuda=args.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/media/h/15210519917/initial_tl/resnet18/20-80_29.pth.tar'\n",
      "=> loaded checkpoint '/media/h/15210519917/initial_tl/resnet18/20-80_29.pth.tar' (epoch 30)\n",
      "creating /media/h/15210519917/initial_tl/resnet18/20-80_29.pt\n",
      "create finished\n"
     ]
    }
   ],
   "source": [
    "for arch in ['resnet18']: #'resnet18', 'resnet34', 'resnet50', 'resnet101', \n",
    "    args.arch = arch\n",
    "    predict(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasize: 43538\n",
      "reading /media/h/15210519917/initial_tl/resnet18/20-80_29.pt\n",
      "torch.Size([43538, 38])\n",
      "torch.Size([43538])\n",
      "0.19011782109737396\n",
      "Acc: 0.94093 [40966/43538], f1: 0.94005, precision: 0.94305, recall: 0.94093, loss: 0.19012\n"
     ]
    }
   ],
   "source": [
    "for arch in ['resnet18']: #'resnet18', 'resnet34', 'resnet50', 'resnet101', \n",
    "    args.arch = arch\n",
    "    predict(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/media/h/15210519917/initial_tl/resnet34/20-80_29.pth.tar'\n",
      "=> loaded checkpoint '/media/h/15210519917/initial_tl/resnet34/20-80_29.pth.tar' (epoch 30)\n",
      "creating /media/h/15210519917/initial_tl/resnet34/20-80_29.pt\n",
      "create finished\n"
     ]
    }
   ],
   "source": [
    "for arch in ['resnet34']: #'resnet18', 'resnet34', 'resnet50', 'resnet101', \n",
    "    args.arch = arch\n",
    "    predict(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasize: 43538\n",
      "reading /media/h/15210519917/initial_tl/resnet34/20-80_29.pt\n",
      "torch.Size([43538, 38])\n",
      "torch.Size([43538])\n",
      "0.20635737478733063\n",
      "Acc: 0.93544 [40727/43538], f1: 0.93564, precision: 0.94082, recall: 0.93544, loss: 0.20636\n"
     ]
    }
   ],
   "source": [
    "for arch in ['resnet34']: #'resnet18', 'resnet34', 'resnet50', 'resnet101', \n",
    "    args.arch = arch\n",
    "    predict(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/media/h/15210519917/initial_tl/resnet50/20-80_29.pth.tar'\n",
      "=> loaded checkpoint '/media/h/15210519917/initial_tl/resnet50/20-80_29.pth.tar' (epoch 30)\n",
      "creating /media/h/15210519917/initial_tl/resnet50/20-80_29.pt\n",
      "create finished\n"
     ]
    }
   ],
   "source": [
    "for arch in ['resnet50']: #'resnet18', 'resnet34', 'resnet50', 'resnet101', \n",
    "    args.arch = arch\n",
    "    predict(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasize: 43538\n",
      "reading /media/h/15210519917/initial_tl/resnet50/20-80_29.pt\n",
      "torch.Size([43538, 38])\n",
      "torch.Size([43538])\n",
      "0.16790658235549927\n",
      "Acc: 0.94899 [41317/43538], f1: 0.94940, precision: 0.95297, recall: 0.94899, loss: 0.16791\n"
     ]
    }
   ],
   "source": [
    "for arch in ['resnet50']: #'resnet18', 'resnet34', 'resnet50', 'resnet101', \n",
    "    args.arch = arch\n",
    "    predict(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/media/h/15210519917/initial_tl/resnet101/20-80_29.pth.tar'\n",
      "=> loaded checkpoint '/media/h/15210519917/initial_tl/resnet101/20-80_29.pth.tar' (epoch 30)\n",
      "creating /media/h/15210519917/initial_tl/resnet101/20-80_29.pt\n",
      "create finished\n"
     ]
    }
   ],
   "source": [
    "for arch in ['resnet101']: #'resnet18', 'resnet34', 'resnet50', 'resnet101', \n",
    "    args.arch = arch\n",
    "    predict(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasize: 43538\n",
      "reading /media/h/15210519917/initial_tl/resnet101/20-80_29.pt\n",
      "torch.Size([43538, 38])\n",
      "torch.Size([43538])\n",
      "0.18912293016910553\n",
      "Acc: 0.94462 [41127/43538], f1: 0.94382, precision: 0.95044, recall: 0.94462, loss: 0.18912\n"
     ]
    }
   ],
   "source": [
    "for arch in ['resnet101']: #'resnet18', 'resnet34', 'resnet50', 'resnet101', \n",
    "    args.arch = arch\n",
    "    predict(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/media/h/15210519917/initial_tl/resnet152/20-80_29.pth.tar'\n",
      "=> loaded checkpoint '/media/h/15210519917/initial_tl/resnet152/20-80_29.pth.tar' (epoch 30)\n",
      "creating /media/h/15210519917/initial_tl/resnet152/20-80_29.pt\n",
      "create finished\n"
     ]
    }
   ],
   "source": [
    "for arch in ['resnet152']: #'resnet18', 'resnet34', 'resnet50', 'resnet101', \n",
    "    args.arch = arch\n",
    "    predict(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasize: 43538\n",
      "reading /media/h/15210519917/initial_tl/resnet152/20-80_29.pt\n",
      "torch.Size([43538, 38])\n",
      "torch.Size([43538])\n",
      "0.20366032421588898\n",
      "Acc: 0.94221 [41022/43538], f1: 0.93851, precision: 0.94504, recall: 0.94221, loss: 0.20366\n"
     ]
    }
   ],
   "source": [
    "for arch in ['resnet152']: #'resnet18', 'resnet34', 'resnet50', 'resnet101', \n",
    "    args.arch = arch\n",
    "    predict(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/media/h/15210519917/initial_tl/resnet18/50-50_29.pth.tar'\n",
      "=> loaded checkpoint '/media/h/15210519917/initial_tl/resnet18/50-50_29.pth.tar' (epoch 30)\n",
      "creating /media/h/15210519917/initial_tl/resnet18/50-50_29.pt\n",
      "create finished\n",
      "=> loading checkpoint '/media/h/15210519917/initial_tl/resnet34/50-50_29.pth.tar'\n",
      "=> loaded checkpoint '/media/h/15210519917/initial_tl/resnet34/50-50_29.pth.tar' (epoch 30)\n",
      "creating /media/h/15210519917/initial_tl/resnet34/50-50_29.pt\n",
      "create finished\n",
      "=> loading checkpoint '/media/h/15210519917/initial_tl/resnet50/50-50_29.pth.tar'\n",
      "=> loaded checkpoint '/media/h/15210519917/initial_tl/resnet50/50-50_29.pth.tar' (epoch 30)\n",
      "creating /media/h/15210519917/initial_tl/resnet50/50-50_29.pt\n",
      "create finished\n",
      "=> loading checkpoint '/media/h/15210519917/initial_tl/resnet101/50-50_29.pth.tar'\n",
      "=> loaded checkpoint '/media/h/15210519917/initial_tl/resnet101/50-50_29.pth.tar' (epoch 30)\n",
      "creating /media/h/15210519917/initial_tl/resnet101/50-50_29.pt\n",
      "create finished\n",
      "=> loading checkpoint '/media/h/15210519917/initial_tl/resnet152/50-50_29.pth.tar'\n",
      "=> loaded checkpoint '/media/h/15210519917/initial_tl/resnet152/50-50_29.pth.tar' (epoch 30)\n",
      "creating /media/h/15210519917/initial_tl/resnet152/50-50_29.pt\n",
      "create finished\n"
     ]
    }
   ],
   "source": [
    "for arch in ['resnet18', 'resnet34', 'resnet50', 'resnet101','resnet152']: #\n",
    "    args.arch = arch\n",
    "    predict(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasize: 27311\n",
      "reading /media/h/15210519917/initial_tl/resnet18/50-50_29.pt\n",
      "torch.Size([27311, 38])\n",
      "torch.Size([27311])\n",
      "0.15847019851207733\n",
      "Acc: 0.95141 [25984/27311], f1: 0.95133, precision: 0.95341, recall: 0.95141, loss: 0.15847\n",
      "datasize: 27311\n",
      "reading /media/h/15210519917/initial_tl/resnet34/50-50_29.pt\n",
      "torch.Size([27311, 38])\n",
      "torch.Size([27311])\n",
      "0.2021794319152832\n",
      "Acc: 0.93633 [25572/27311], f1: 0.93904, precision: 0.94806, recall: 0.93633, loss: 0.20218\n",
      "datasize: 27311\n",
      "reading /media/h/15210519917/initial_tl/resnet50/50-50_29.pt\n",
      "torch.Size([27311, 38])\n",
      "torch.Size([27311])\n",
      "0.14000412821769714\n",
      "Acc: 0.95723 [26143/27311], f1: 0.95868, precision: 0.96397, recall: 0.95723, loss: 0.14000\n",
      "datasize: 27311\n",
      "reading /media/h/15210519917/initial_tl/resnet101/50-50_29.pt\n",
      "torch.Size([27311, 38])\n",
      "torch.Size([27311])\n",
      "0.14586341381072998\n",
      "Acc: 0.95548 [26095/27311], f1: 0.95589, precision: 0.95950, recall: 0.95548, loss: 0.14586\n",
      "datasize: 27311\n",
      "reading /media/h/15210519917/initial_tl/resnet152/50-50_29.pt\n",
      "torch.Size([27311, 38])\n",
      "torch.Size([27311])\n",
      "0.1994190365076065\n",
      "Acc: 0.93468 [25527/27311], f1: 0.93366, precision: 0.94193, recall: 0.93468, loss: 0.19942\n"
     ]
    }
   ],
   "source": [
    "for arch in ['resnet18', 'resnet34', 'resnet50', 'resnet101','resnet152']: #\n",
    "    args.arch = arch\n",
    "    predict(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
